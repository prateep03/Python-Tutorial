{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Recommender systems are among the most popular applications of data science today. They are used to predict the *rating* or *preference* that an user would give to an item. Amazon uses it to suggest products to customers. YouTube uses recommender systems to decide which video to play next on autoplay.\n",
    "\n",
    "There are also popular recommder systems for domains like restaurants and movies. Recommender systems have also been developed to explore research articles and experts, collaborators and financial services. YouTube uses the recommendation system at a large scale to suggest videos based on your history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems can be classified primarily into 3 types:\n",
    "\n",
    "- <u>Simple recommenders</u>: Offer generalized recommendations to every user, based on movie popularity and/or genre.  The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience. For example, IMDB Top 250.\n",
    "\n",
    "- <u> Content-based recommenders</u>: These recommenders suggest similar items based on a particular item. This system uses item metadata, such as genre, director, actors etc, for movies, to make these recommendations. The general idea behind these systems is that if a person likes a particular item, he will also like an item that is similar to it. And to recommend that, it will make use of the user's past item metadata. For example, YouTube, where based on your history, the system suggests new videos that you can potentially watch.\n",
    "\n",
    "- <u> Collaborative filtering</u>: These systems are widely used, and they try to predict the rating or preference that an user would give an item-based on past ratings and preferences of other  users. Collaborative filtering based recommendation systems do not require item metadata like content-based ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset files contain metadata for 9742 movies listed in the [`MovieLens Dataset`](https://grouplens.org/datasets/movielens/). The dataset consists of movies released on or before September 2018. The dataset captures feature points like cast, crew, TMDB vote counts and vote averages.\n",
    "\n",
    "This dataset consists of the following files:\n",
    "\n",
    "* *movies.csv*: Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "*****\n",
    "    movieId,title,genres\n",
    "*****\n",
    "\n",
    "Genres are a a pipe-separated list. Some common genres are: Action, Adventure, Animation, Comedy, Crime etc.\n",
    "\n",
    "* *links.csv*: This file contains the TMDB and IMDB IDs of all the movies featured in the `MovieLens Dataset`.\n",
    "\n",
    "* *ratings.csv*: This file contains 100836 ratings across 9742 movies from 610 users. Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", palette=\"icefire\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\Teaching\\Python-Tutorial\\data\\ml-latest-small')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ratings` DataFrame contains the IDs of the movies but not their titles. We'll need movie names for the movies we're recommending. We can merge the above two DataFrames, based on the column `movieId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.merge(movies, ratings, on=\"movieId\")\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add a column to the above DataFrame, which represents the average rating of each movie. To do so, we can group the dataset by the title of the movie and then calculate the mean of the rating for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_average = pd.DataFrame(metadata.groupby('title')['rating'].mean())\n",
    "vote_count = pd.DataFrame(metadata.groupby('title')['rating'].count())\n",
    "\n",
    "vote_average.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ratings and count\n",
    "d_movies = pd.merge(movies, vote_average, on='title', how='left')\n",
    "d_movies = pd.merge(d_movies, vote_count, on='title', how='left')\n",
    "\n",
    "# Rename columns to vote_average and vote_count\n",
    "d_movies = d_movies.rename(columns={'rating_x' : 'vote_average', 'rating_y': 'vote_count'})\n",
    "\n",
    "d_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us join `tags` column as well. Each tag is typically a single word or short phrase. The meaning, value and purpose of a particular tag is determined by the user. Note that some movies are also present in our DataFrame with no tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('tags.csv')\n",
    "\n",
    "tags_df = pd.DataFrame(tags.groupby('movieId')['tag'].apply(lambda x: '{}'.format('|'.join(x))))\n",
    "\n",
    "d_movies = pd.merge(d_movies, tags_df, on='movieId', how='left')\n",
    "d_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us also join the TMDB and IMDB IDs so as to generate the complete matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('links.csv')\n",
    "\n",
    "d_movies = pd.merge(d_movies, links, on='movieId', how='left')\n",
    "d_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Recommender System\n",
    "\n",
    "To compute *fairly* the popularity of a movie, we should calculate its weighted rating score. This score takes into account the average rating and the number of votes a movie has accumulated. Such a score would make sure that a movie with a 9 rating from 100k voters gets a higher score than a movie with the same rating but from 100 voters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the weighted rating score is formulated as:\n",
    "\n",
    "$$\n",
    "\\mathbf{S} = \\left( \\frac{v}{v + m} \\cdot \\mathbf{R} \\right) + \\left( \\frac{m}{v + m} \\cdot \\mathbf{C} \\right) \n",
    "$$\n",
    "\n",
    "where,\n",
    "* $v$: number of votes for a movie(column: `vote_count`),\n",
    "* $m$: minimum no of votes required to be listed in a chart,\n",
    "* $\\mathbf{R}$: average rating of the movie(column: `vote_average`),\n",
    "* $\\mathbf{C}$: mean vote across all movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of $m$ simply removes the movies which have number of votes less than a certain threshold. For our case, let us select this threshold to be $90^{th}$ percentile. In other words, for a movie to be featured in the charts, it must have more votes than at least 90% of the movies on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of vote_average column, C\n",
    "C = d_movies['vote_average'].mean()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min number of votes required to be in the chart, m\n",
    "m = d_movies['vote_count'].quantile(0.90)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine the `d_movies` DataFrame based on these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_movies = d_movies.copy().loc[d_movies['vote_count'] >= m]\n",
    "\n",
    "print(d_movies.shape)\n",
    "print(t_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "978./9742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, it is clear that there are around 10% movies with vote count more than 27 and qualify to be on this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us calculate the weighted rating for each qualified movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_score(x, m=m, C=C):\n",
    "    try:\n",
    "        v = x['vote_count']\n",
    "        R = x['vote_average']\n",
    "        \n",
    "        return (v/(v+m) * R) + (m/(v+m) * C)\n",
    "    except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_movies['score'] = t_movies.apply(weighted_score, axis=1)\n",
    "\n",
    "t_movies.sort_values('score',ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "There are two types of Collaborative Filtering,\n",
    "\n",
    "1. User-based filtering\n",
    "2. Item-based filtering\n",
    "\n",
    "\n",
    "**User-based filtering**\n",
    "\n",
    "\n",
    "This approach is often harder to scale because of the user count increase rapidly and recommendation for the new user is bit harder.\n",
    "\n",
    "**Item-based filtering**\n",
    "\n",
    "This approach is mostly preferred since the movie don't change much. We can rerun this model once a week unlike User based where we have to frequently run the model.\n",
    "\n",
    "In this notebook, we will look at the item-based filtering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_movies = ratings.pivot(index=\"movieId\", columns=\"userId\", values=\"rating\")\n",
    "\n",
    "# Fill missing rating with 0s\n",
    "d_movies.fillna(0,inplace=True)\n",
    "\n",
    "d_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we must squeeze the matrix by adding some filters and qualify the movies for this dataset.\n",
    "\n",
    "- To qualify a movie, minimum of 10 users should be voted the movie.\n",
    "- To qualify a user, minimum 50 movies should be voted by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_user_voted = ratings.groupby('movieId')['rating'].agg('count')\n",
    "no_movies_voted = ratings.groupby('userId')['rating'].agg('count')\n",
    "\n",
    "t_movies = d_movies.loc[no_user_voted[no_user_voted > 10].index, no_movies_voted[no_movies_voted > 50].index]\n",
    "print(t_movies.shape)\n",
    "t_movies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the sparsity of this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 1.0 - ( np.count_nonzero(t_movies.values) / float(t_movies.size) )\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our matrix is 90% sparse. This is a common scenario for recommendation systems, where not all products are voted by a user. To work more efficiently with sparse matrices, we shall use the `csr_matrix` sub-module from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "t_csr = csr_matrix(t_movies.values)\n",
    "t_movies.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute movie recommendations, we must compute *cosine similarity* for a movie from its neighbors. For this, we would use `NearestNeighbors` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "knn.fit(t_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_recommendation(movie_name):\n",
    "    n_recommendations = 1\n",
    "    movie_list = movies[movies['title'].str.contains(movie_name)]\n",
    "    if len(movie_list) > 0:\n",
    "        movie_idx = movie_list.iloc[0]['movieId']\n",
    "        movie_idx = t_movies[t_movies['movieId'] == movie_idx].index[0]\n",
    "        print(movie_idx)\n",
    "        \n",
    "        distances , indices = knn.kneighbors(t_csr[movie_idx],n_neighbors=n_recommendations+1)    \n",
    "        rec_movie_indices = sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),\\\n",
    "                               key=lambda x: x[1])[:0:-1]\n",
    "        print(rec_movie_indices)\n",
    "        \n",
    "        recommend_frame = []\n",
    "        \n",
    "        for val in rec_movie_indices:\n",
    "            movie_idx = t_movies.iloc[val[0]]['movieId']\n",
    "            idx = movies[movies['movieId'] == movie_idx].index\n",
    "            recommend_frame.append({'Title':movies.iloc[idx]['title'].values[0],'Distance':val[1]})\n",
    "            \n",
    "        df = pd.DataFrame(recommend_frame,index=range(1,n_recommendations+1))\n",
    "        return df\n",
    "    else:\n",
    "        print('No movie found with this name {}'.format(movie_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_movie_recommendation('Godfather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
